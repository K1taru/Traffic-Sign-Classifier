{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bc60c8",
   "metadata": {},
   "source": [
    "# Traffic Sign Classifier - Inference Application\n",
    "\n",
    "This notebook loads the trained GTSRB traffic sign classifier model and performs inference on:\n",
    "- **Images** stored in `input/` folder\n",
    "- **Videos** (optional) - extracts frames and classifies traffic signs\n",
    "\n",
    "**Model Used:** `GTSRB_resnet50_E18_VAL100.00.pth`  \n",
    "**Classes:** 43 German Traffic Sign classes\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Place your images or videos** in the `input/` folder\n",
    "2. **Run all cells** in order (Cell ‚Üí Run All)\n",
    "3. **View results** with predicted classes and confidence scores\n",
    "\n",
    "**Supported Formats:**\n",
    "- Images: `.png`, `.jpg`, `.jpeg`, `.bmp`, `.tiff`, `.webp`\n",
    "- Videos: `.mp4`, `.avi`, `.mov`, `.mkv`, `.wmv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6426b578",
   "metadata": {},
   "source": [
    "### 2. Configuration and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329dfca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a467d1",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b252c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Configuration\n",
    "# =======================================\n",
    "MODEL_PATH = \"model/GTSRB_resnet50_E18_VAL100.00.pth\"\n",
    "INPUT_FOLDER = \"input\"\n",
    "NUM_CLASSES = 43  # GTSRB has 43 traffic sign classes\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c61619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° No videos found in input folder.\n",
      "   To process videos, add .mp4, .avi, or other video files to: input/\n"
     ]
    }
   ],
   "source": [
    "# Process videos in input folder (optional)\n",
    "valid_video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.wmv')\n",
    "\n",
    "video_files = [f for f in os.listdir(INPUT_FOLDER) \n",
    "               if f.lower().endswith(valid_video_extensions)]\n",
    "\n",
    "if video_files:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üé¨ Found {len(video_files)} video(s) in input folder\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for video_filename in video_files:\n",
    "        video_path = os.path.join(INPUT_FOLDER, video_filename)\n",
    "        print(f\"üìπ Processing: {video_filename}\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        \n",
    "        try:\n",
    "            video_results = process_video(video_path, model, preprocess, device, class_names, frame_interval=30)\n",
    "            print(f\"{'‚îÄ'*80}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing video {video_filename}: {str(e)}\\n\")\n",
    "else:\n",
    "    print(f\"\\nüí° No videos found in input folder.\")\n",
    "    print(f\"   To process videos, add .mp4, .avi, or other video files to: {INPUT_FOLDER}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b09be3",
   "metadata": {},
   "source": [
    "### 8. Video Processing Function (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06fab24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Video processing function defined\n"
     ]
    }
   ],
   "source": [
    "def process_video(video_path, model, preprocess, device, class_names, frame_interval=30):\n",
    "    \"\"\"\n",
    "    Process video and classify traffic signs in sampled frames.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        model: Trained PyTorch model\n",
    "        preprocess: Preprocessing transforms\n",
    "        device: torch device (cuda/cpu)\n",
    "        class_names: Dictionary mapping class IDs to names\n",
    "        frame_interval: Process every Nth frame (default: 30)\n",
    "        \n",
    "    Returns:\n",
    "        List of predictions for sampled frames\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error: Cannot open video {video_path}\")\n",
    "        return []\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"üìπ Video Info:\")\n",
    "    print(f\"   FPS: {fps:.2f}\")\n",
    "    print(f\"   Total Frames: {total_frames}\")\n",
    "    print(f\"   Processing every {frame_interval} frames\\n\")\n",
    "    \n",
    "    results = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process every Nth frame\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # Convert BGR to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame_rgb)\n",
    "            \n",
    "            # Preprocess and predict\n",
    "            img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(img_tensor)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                confidence, predicted_class = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_id = predicted_class.item()\n",
    "            predicted_label = class_names.get(predicted_id, f\"Unknown ({predicted_id})\")\n",
    "            conf_percentage = confidence.item() * 100\n",
    "            \n",
    "            timestamp = frame_count / fps\n",
    "            \n",
    "            result = {\n",
    "                \"frame\": frame_count,\n",
    "                \"timestamp\": f\"{timestamp:.2f}s\",\n",
    "                \"predicted_class_id\": predicted_id,\n",
    "                \"predicted_class_name\": predicted_label,\n",
    "                \"confidence\": conf_percentage\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"‚è±Ô∏è  Frame {frame_count} ({timestamp:.2f}s): {predicted_label} ({conf_percentage:.2f}%)\")\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"\\n‚úÖ Processed {len(results)} frames from video\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Video processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c7b17",
   "metadata": {},
   "source": [
    "### 9. Process Videos in Input Folder (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7538d47",
   "metadata": {},
   "source": [
    "### 7. Process All Images in Input Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f2f88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç Scanning input folder: input\n",
      "================================================================================\n",
      "\n",
      "üìÅ Found 1 image(s)\n",
      "\n",
      "üì∑ images.png\n",
      "   üè∑Ô∏è  Predicted: Class 1\n",
      "   üéØ Confidence: 21.34%\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Processed 1/1 images successfully\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Process all images in input folder\n",
    "valid_image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üîç Scanning input folder: {INPUT_FOLDER}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "image_files = [f for f in os.listdir(INPUT_FOLDER) \n",
    "               if f.lower().endswith(valid_image_extensions)]\n",
    "\n",
    "if not image_files:\n",
    "    print(\"‚ö†Ô∏è  No images found in input folder!\")\n",
    "    print(f\"   Please add images to: {INPUT_FOLDER}/\")\n",
    "    print(f\"   Supported formats: {', '.join(valid_image_extensions)}\")\n",
    "else:\n",
    "    print(f\"üìÅ Found {len(image_files)} image(s)\\n\")\n",
    "    \n",
    "    results = []\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(INPUT_FOLDER, filename)\n",
    "        \n",
    "        try:\n",
    "            result = predict_image(img_path, model, preprocess, device, class_names)\n",
    "            results.append(result)\n",
    "            \n",
    "            print(f\"üì∑ {result['file']}\")\n",
    "            print(f\"   üè∑Ô∏è  Predicted: {result['predicted_class_name']}\")\n",
    "            print(f\"   üéØ Confidence: {result['confidence']:.2f}%\")\n",
    "            print(f\"   {'‚îÄ'*60}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {filename}: {str(e)}\")\n",
    "            print(f\"   {'‚îÄ'*60}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ Processed {len(results)}/{len(image_files)} images successfully\")\n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8dab21",
   "metadata": {},
   "source": [
    "### 6. Inference Function for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83e2f32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Image inference function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model, preprocess, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict traffic sign class for a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        model: Trained PyTorch model\n",
    "        preprocess: Preprocessing transforms\n",
    "        device: torch device (cuda/cpu)\n",
    "        class_names: Dictionary mapping class IDs to names\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_id = predicted_class.item()\n",
    "    predicted_label = class_names.get(predicted_id, f\"Unknown ({predicted_id})\")\n",
    "    conf_percentage = confidence.item() * 100\n",
    "    \n",
    "    return {\n",
    "        \"file\": os.path.basename(image_path),\n",
    "        \"predicted_class_id\": predicted_id,\n",
    "        \"predicted_class_name\": predicted_label,\n",
    "        \"confidence\": conf_percentage\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Image inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265272c",
   "metadata": {},
   "source": [
    "### 5. Define Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "116235c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing pipeline defined\n"
     ]
    }
   ],
   "source": [
    "# Image preprocessing (same as training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Preprocessing pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85f108",
   "metadata": {},
   "source": [
    "### 4. Load Class Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acdd37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 43 class names from Meta.csv\n"
     ]
    }
   ],
   "source": [
    "# Load class names from Meta.csv\n",
    "meta_path = \"../dataset/Meta.csv\"\n",
    "if os.path.exists(meta_path):\n",
    "    meta_df = pd.read_csv(meta_path)\n",
    "    class_names = {row['ClassId']: f\"Class {row['ClassId']}\" for _, row in meta_df.iterrows()}\n",
    "    print(f\"‚úÖ Loaded {len(class_names)} class names from Meta.csv\")\n",
    "else:\n",
    "    # Fallback: use generic class names\n",
    "    class_names = {i: f\"Class {i}\" for i in range(NUM_CLASSES)}\n",
    "    print(f\"‚ö†Ô∏è  Meta.csv not found, using generic class names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae6e3f",
   "metadata": {},
   "source": [
    "### 3. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "427d7069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading model...\n",
      "‚úÖ Model loaded successfully!\n",
      "   Architecture: ResNet50\n",
      "   Classes: 43\n",
      "   Best Epoch: 18\n",
      "   Validation Accuracy: 100.00%\n",
      "‚úÖ Model loaded successfully!\n",
      "   Architecture: ResNet50\n",
      "   Classes: 43\n",
      "   Best Epoch: 18\n",
      "   Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the trained ResNet50 model\n",
    "print(\"üîÑ Loading model...\")\n",
    "\n",
    "# Recreate model architecture\n",
    "model = models.resnet50(weights=None)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(in_features, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Architecture: ResNet50\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")\n",
    "print(f\"   Best Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"   Validation Accuracy: {checkpoint['val_acc']*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6ffd63",
   "metadata": {},
   "source": [
    "## Traffic Sign Classifier - GTSRB Dataset\n",
    "### German Traffic Sign Recognition Benchmark (GTSRB)\n",
    "\n",
    "This notebook implements a deep learning model to classify German traffic signs using the GTSRB dataset.\n",
    "The dataset contains 43 classes of traffic signs with pre-split training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    classification_report,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Custom imports\n",
    "from utils.gpu_utils import CheckGPU, CheckCUDA, CheckGPUBrief\n",
    "from utils.gtsrb_dataset import (\n",
    "    GTSRBDataset, \n",
    "    load_gtsrb_info, \n",
    "    print_gtsrb_summary,\n",
    "    print_class_distribution_table\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All libraries and custom modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3294f",
   "metadata": {},
   "source": [
    "#### Detect GPU Available, Details, Cuda, and cuDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From utils.gpu_utils\n",
    "CheckGPU()\n",
    "CheckCUDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a820654",
   "metadata": {},
   "source": [
    "### Global Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# GLOBAL CONFIGURATION\n",
    "# ============================\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_DIR = \"../dataset\"\n",
    "TRAIN_CSV = os.path.join(DATASET_DIR, \"Train.csv\")\n",
    "TEST_CSV = os.path.join(DATASET_DIR, \"Test.csv\")\n",
    "META_CSV = os.path.join(DATASET_DIR, \"Meta.csv\")\n",
    "\n",
    "# GTSRB has pre-split train/test, we'll create validation from training set\n",
    "VALIDATION_SPLIT = 0.10  # 10% of training data for validation (90% train, 10% val)\n",
    "\n",
    "# ROI (Region of Interest) Cropping\n",
    "USE_ROI_CROP = True  # Crop images to sign bounding box before processing\n",
    "\n",
    "# Augmentation settings\n",
    "USE_AUGMENTATION = True\n",
    "\n",
    "# Weighted sampling for class imbalance\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# Normalization values\n",
    "# Option 1: Use ImageNet pretrained values (recommended for transfer learning)\n",
    "USE_IMAGENET_NORM = True\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Option 2: Compute from GTSRB dataset (set USE_IMAGENET_NORM = False to use these)\n",
    "GTSRB_MEAN = [0.3403, 0.3121, 0.3214]  # Will be computed if needed\n",
    "GTSRB_STD = [0.2724, 0.2608, 0.2669]   # Will be computed if needed\n",
    "\n",
    "# Set normalization based on choice\n",
    "if USE_IMAGENET_NORM:\n",
    "    NORMALIZE_MEAN = IMAGENET_MEAN\n",
    "    NORMALIZE_STD = IMAGENET_STD\n",
    "    print(\"üìä Using ImageNet normalization values (recommended for transfer learning)\")\n",
    "else:\n",
    "    NORMALIZE_MEAN = GTSRB_MEAN\n",
    "    NORMALIZE_STD = GTSRB_STD\n",
    "    print(\"üìä Using GTSRB-specific normalization values\")\n",
    "\n",
    "# Image settings\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Batch size & Classes\n",
    "BATCH_SIZE = 48  # Increased for traffic signs (smaller images)\n",
    "NUM_CLASSES = 43  # GTSRB has 43 traffic sign classes\n",
    "\n",
    "# Model Architecture Selection\n",
    "# Options: 'resnet50' or 'efficientnet_b3'\n",
    "MODEL_ARCH = 'resnet50'  # Change this to 'efficientnet_b3' to switch models\n",
    "\n",
    "# Model save path\n",
    "MODEL_SAVE_DIR = \"../models\"\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"‚úÖ Global configuration set successfully!\")\n",
    "print(f\"   Dataset: {DATASET_DIR}\")\n",
    "print(f\"   Model Architecture: {MODEL_ARCH.upper()}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")\n",
    "print(f\"   Image Size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Validation Split: {VALIDATION_SPLIT*100:.0f}%\")\n",
    "print(f\"   ROI Crop: {'ENABLED' if USE_ROI_CROP else 'DISABLED'}\")\n",
    "print(f\"   Augmentation: {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
    "print(f\"   Weighted Sampler: {'ENABLED' if USE_WEIGHTED_SAMPLER else 'DISABLED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219a799",
   "metadata": {},
   "source": [
    "### GTSRB Dataset Analysis & Information\n",
    "\n",
    "Load and analyze the GTSRB dataset structure, class distribution, and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac14c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GTSRB dataset information\n",
    "print(\"üîç Loading GTSRB dataset information...\")\n",
    "dataset_info = load_gtsrb_info(DATASET_DIR)\n",
    "\n",
    "# Print comprehensive summary\n",
    "print_gtsrb_summary(dataset_info)\n",
    "\n",
    "# Print detailed class distribution\n",
    "print_class_distribution_table(dataset_info, top_n=10)\n",
    "\n",
    "print(\"\\n‚úÖ Dataset information loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac331117",
   "metadata": {},
   "source": [
    "### Visualize Sample Images from Dataset\n",
    "\n",
    "Display sample traffic signs from each class to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from different classes\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(\"üñºÔ∏è  Displaying sample traffic signs from dataset...\")\n",
    "\n",
    "# Select 12 random classes to display\n",
    "num_samples = 12\n",
    "random_classes = np.random.choice(NUM_CLASSES, size=min(num_samples, NUM_CLASSES), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "for idx, class_id in enumerate(random_classes):\n",
    "    # Get a random sample from this class\n",
    "    class_samples = train_df[train_df['ClassId'] == class_id]\n",
    "    sample_idx = np.random.choice(len(class_samples))\n",
    "    sample_row = class_samples.iloc[sample_idx]\n",
    "    \n",
    "    # Load and display image\n",
    "    img_path = os.path.join(DATASET_DIR, sample_row['Path'])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Apply ROI crop if enabled\n",
    "    if USE_ROI_CROP:\n",
    "        roi_x1, roi_y1 = sample_row['Roi.X1'], sample_row['Roi.Y1']\n",
    "        roi_x2, roi_y2 = sample_row['Roi.X2'], sample_row['Roi.Y2']\n",
    "        img = img.crop((roi_x1, roi_y1, roi_x2, roi_y2))\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Class {class_id}\\n{sample_row[\"Width\"]}x{sample_row[\"Height\"]}px', \n",
    "                        fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Sample Traffic Signs from GTSRB Dataset', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc9191",
   "metadata": {},
   "source": [
    "### Data Augmentation & Transforms\n",
    "\n",
    "Define transforms for training (with augmentation) and validation/test sets.\n",
    "GTSRB-specific augmentations optimized for traffic sign recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_AUGMENTATION:\n",
    "    # Training augmentation - optimized for traffic signs\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        # Geometric augmentations (moderate for traffic signs)\n",
    "        transforms.RandomRotation(15),  # Signs can be at slight angles\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        # Color augmentations (helps with lighting variations)\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "        # Random perspective (simulates viewing angle)\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "        # Convert to tensor\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize\n",
    "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "        # Random erasing (simulates occlusion/dirt)\n",
    "        transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n",
    "    ])\n",
    "    print(\"‚úÖ Training augmentation ENABLED\")\n",
    "    print(\"   - Rotation: ¬±15¬∞\")\n",
    "    print(\"   - Translation: ¬±10%\")\n",
    "    print(\"   - Scale: 90-110%\")\n",
    "    print(\"   - Color jitter: brightness/contrast/saturation/hue\")\n",
    "    print(\"   - Perspective distortion\")\n",
    "    print(\"   - Random erasing (occlusion simulation)\")\n",
    "else:\n",
    "    # No augmentation\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
    "    ])\n",
    "    print(\"‚ö†Ô∏è  Training augmentation DISABLED\")\n",
    "\n",
    "# Validation and test transforms (no augmentation)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
    "])\n",
    "\n",
    "print(f\"‚úÖ Transforms defined successfully!\")\n",
    "print(f\"   Target size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"   Normalization: Mean={NORMALIZE_MEAN}, Std={NORMALIZE_STD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7026553",
   "metadata": {},
   "source": [
    "### Load GTSRB Datasets\n",
    "\n",
    "Load the pre-split training and test sets from CSV files.\n",
    "Create validation set by splitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full training dataset (will split into train/val)\n",
    "print(\"üìÇ Loading GTSRB training dataset...\")\n",
    "full_train_dataset = GTSRBDataset(\n",
    "    csv_path=TRAIN_CSV,\n",
    "    root_dir=DATASET_DIR,\n",
    "    transform=None,  # Will assign transforms after split\n",
    "    use_roi=USE_ROI_CROP\n",
    ")\n",
    "\n",
    "# Load test dataset\n",
    "print(\"üìÇ Loading GTSRB test dataset...\")\n",
    "test_dataset = GTSRBDataset(\n",
    "    csv_path=TEST_CSV,\n",
    "    root_dir=DATASET_DIR,\n",
    "    transform=val_test_transforms,  # No augmentation for test\n",
    "    use_roi=USE_ROI_CROP\n",
    ")\n",
    "\n",
    "num_total_train = len(full_train_dataset)\n",
    "num_test = len(test_dataset)\n",
    "\n",
    "print(f\"‚úÖ Datasets loaded successfully!\")\n",
    "print(f\"   Training samples (before split): {num_total_train:,}\")\n",
    "print(f\"   Test samples: {num_test:,}\")\n",
    "\n",
    "# Split training into train and validation\n",
    "val_size = int(VALIDATION_SPLIT * num_total_train)\n",
    "train_size = num_total_train - val_size\n",
    "\n",
    "# Use random_split to create train/val indices\n",
    "train_subset, val_subset = random_split(\n",
    "    full_train_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training data split completed:\")\n",
    "print(f\"   üîπ Train: {train_size:,} samples ({(1-VALIDATION_SPLIT)*100:.0f}%)\")\n",
    "print(f\"   üîπ Validation: {val_size:,} samples ({VALIDATION_SPLIT*100:.0f}%)\")\n",
    "print(f\"   üîπ Test: {num_test:,} samples (separate set)\")\n",
    "\n",
    "# Assign transforms to subsets\n",
    "train_subset.dataset.transform = train_transforms\n",
    "val_subset.dataset.transform = val_test_transforms\n",
    "\n",
    "print(f\"\\n‚úÖ Transforms assigned:\")\n",
    "print(f\"   Train: Augmentation {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
    "print(f\"   Validation/Test: No augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c1fc5",
   "metadata": {},
   "source": [
    "### Compute Class Weights for Imbalanced Data\n",
    "\n",
    "Calculate class weights to handle the imbalanced GTSRB dataset.\n",
    "This helps the model learn minority classes better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b96c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class distribution from training data\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "class_counts = train_df['ClassId'].value_counts().sort_index().values\n",
    "\n",
    "print(f\"üìä Class distribution in training set:\")\n",
    "print(f\"   Total classes: {len(class_counts)}\")\n",
    "print(f\"   Most populated class: {class_counts.max():,} samples\")\n",
    "print(f\"   Least populated class: {class_counts.min():,} samples\")\n",
    "print(f\"   Average per class: {class_counts.mean():.1f} samples\")\n",
    "print(f\"   Imbalance ratio: {class_counts.max() / class_counts.min():.2f}x\")\n",
    "\n",
    "# Compute class weights (inverse frequency)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize\n",
    "\n",
    "print(f\"\\nüìê Class weights computed:\")\n",
    "print(f\"   Min weight: {class_weights.min():.4f}\")\n",
    "print(f\"   Max weight: {class_weights.max():.4f}\")\n",
    "print(f\"   Weight ratio: {class_weights.max() / class_weights.min():.2f}x\")\n",
    "\n",
    "# Create sample weights for WeightedRandomSampler\n",
    "if USE_WEIGHTED_SAMPLER:\n",
    "    # Get labels from training subset\n",
    "    train_indices = train_subset.indices\n",
    "    train_labels = [train_df.iloc[idx]['ClassId'] for idx in train_indices]\n",
    "    sample_weights = [class_weights[label] for label in train_labels]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Weighted sampler initialized for {len(sample_weights):,} training samples\")\n",
    "else:\n",
    "    sample_weights = None\n",
    "    print(\"\\n‚ö†Ô∏è  Weighted sampler DISABLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1afa8a4",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "Initialize PyTorch DataLoaders with appropriate batch size and sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training DataLoader\n",
    "if USE_WEIGHTED_SAMPLER:\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=sampler,\n",
    "        num_workers=0,  # Set to 0 for Windows compatibility\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"‚úÖ Train DataLoader: {len(train_subset):,} samples with WeightedRandomSampler\")\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"‚úÖ Train DataLoader: {len(train_subset):,} samples with shuffle=True\")\n",
    "\n",
    "# Create validation DataLoader\n",
    "val_loader = DataLoader(\n",
    "    val_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "print(f\"‚úÖ Validation DataLoader: {len(val_subset):,} samples\")\n",
    "\n",
    "# Create test DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "print(f\"‚úÖ Test DataLoader: {len(test_dataset):,} samples\")\n",
    "\n",
    "print(f\"\\nüì¶ Batch configuration:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b83e75",
   "metadata": {},
   "source": [
    "#### PRINT SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Dataset:':<30} GTSRB (German Traffic Signs)\")\n",
    "print(f\"{'Total Classes:':<30} {NUM_CLASSES}\")\n",
    "print(f\"{'Training Samples:':<30} {train_size:,}\")\n",
    "print(f\"{'Validation Samples:':<30} {val_size:,}\")\n",
    "print(f\"{'Test Samples:':<30} {num_test:,}\")\n",
    "print(f\"{'Total Samples:':<30} {train_size + val_size + num_test:,}\")\n",
    "print(f\"\\n{'Image Processing:':<30}\")\n",
    "print(f\"  {'- Target Size:':<28} {IMG_HEIGHT}x{IMG_WIDTH} pixels\")\n",
    "print(f\"  {'- ROI Cropping:':<28} {'ENABLED' if USE_ROI_CROP else 'DISABLED'}\")\n",
    "print(f\"  {'- Normalization:':<28} {'ImageNet' if USE_IMAGENET_NORM else 'GTSRB'}\")\n",
    "print(f\"\\n{'Augmentation:':<30} {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
    "if USE_AUGMENTATION:\n",
    "    print(f\"  - Rotation, Translation, Scale, Color Jitter, Perspective, Erasing\")\n",
    "print(f\"\\n{'Class Balancing:':<30}\")\n",
    "print(f\"  {'- Weighted Sampling:':<28} {'ENABLED' if USE_WEIGHTED_SAMPLER else 'DISABLED'}\")\n",
    "print(f\"  {'- Class Imbalance Ratio:':<28} {class_counts.max() / class_counts.min():.2f}x\")\n",
    "print(f\"\\n{'Batch Configuration:':<30}\")\n",
    "print(f\"  {'- Batch Size:':<28} {BATCH_SIZE}\")\n",
    "print(f\"  {'- Train Batches/Epoch:':<28} {len(train_loader)}\")\n",
    "print(f\"  {'- Val Batches/Epoch:':<28} {len(val_loader)}\")\n",
    "print(f\"  {'- Test Batches:':<28} {len(test_loader)}\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ Preprocessing complete! Ready for model training.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5e7fa",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING KEY VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af63cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# MODEL TRAINING CONFIGURATION\n",
    "# ============================\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 0.0001\n",
    "MAX_EPOCHS = 30  # Maximum training epochs\n",
    "WEIGHT_DECAY = 1e-4  # L2 regularization to prevent overfitting\n",
    "DROPOUT_RATE = 0.4  # Dropout in classifier head\n",
    "\n",
    "# Early stopping\n",
    "EARLY_STOPPING_PATIENCE = 5  # Stop if no improvement for 5 epochs\n",
    "\n",
    "# Gradient clipping\n",
    "MAX_GRAD_NORM = 1.0  # Prevent exploding gradients\n",
    "\n",
    "# Training history dictionary (global)\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"train_top5_acc\": [],\n",
    "    \"val_top5_acc\": [],\n",
    "    \"learning_rates\": []\n",
    "}\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "print(f\"   Model: {MODEL_ARCH.upper()}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Weight Decay: {WEIGHT_DECAY}\")\n",
    "print(f\"   Dropout Rate: {DROPOUT_RATE}\")\n",
    "print(f\"   Max Epochs: {MAX_EPOCHS}\")\n",
    "print(f\"   Early Stopping Patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf0335",
   "metadata": {},
   "source": [
    "### Load Pretrained Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df73050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model based on MODEL_ARCH configuration\n",
    "CheckCUDA()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if MODEL_ARCH == 'resnet50':\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    print(\"‚úÖ Pre-trained ResNet50 loaded (weights: IMAGENET1K_V1)\")\n",
    "    \n",
    "    # Replace classifier head with dropout\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(in_features, NUM_CLASSES)\n",
    "    )\n",
    "    print(f\"‚úÖ Classifier replaced: {in_features} ‚Üí Dropout({DROPOUT_RATE}) ‚Üí {NUM_CLASSES} classes\")\n",
    "\n",
    "elif MODEL_ARCH == 'efficientnet_b3':\n",
    "    model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "    print(\"‚úÖ Pre-trained EfficientNet-B3 loaded (weights: IMAGENET1K_V1)\")\n",
    "    \n",
    "    # Replace classifier head with dropout\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE, inplace=True),\n",
    "        nn.Linear(in_features, NUM_CLASSES)\n",
    "    )\n",
    "    print(f\"‚úÖ Classifier replaced: {in_features} ‚Üí Dropout({DROPOUT_RATE}) ‚Üí {NUM_CLASSES} classes\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model architecture: {MODEL_ARCH}. Choose 'resnet50' or 'efficientnet_b3'\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "print(f\"‚úÖ Model moved to device: {device.type.upper()}\")\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d9c72",
   "metadata": {},
   "source": [
    "#### LOSS & OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class weights\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "print(f\"‚úÖ Loss function: CrossEntropyLoss with class weights\")\n",
    "\n",
    "# Adam optimizer with weight decay (L2 regularization)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "print(f\"‚úÖ Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "\n",
    "# Learning rate scheduler - ReduceLROnPlateau (reduces LR when validation loss plateaus)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    verbose=True,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "print(f\"‚úÖ LR Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff464d39",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"üöÄ MODEL SETUP COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Architecture:':<25} {MODEL_ARCH.upper()}\")\n",
    "print(f\"{'Input Size:':<25} {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"{'Output Classes:':<25} {NUM_CLASSES}\")\n",
    "print(f\"{'Total Parameters:':<25} {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"{'Trainable Parameters:':<25} {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"\\\\n{'Training Settings:':<25}\")\n",
    "print(f\"{'  Learning Rate:':<25} {LEARNING_RATE}\")\n",
    "print(f\"{'  Weight Decay:':<25} {WEIGHT_DECAY}\")\n",
    "print(f\"{'  Dropout Rate:':<25} {DROPOUT_RATE}\")\n",
    "print(f\"{'  Max Epochs:':<25} {MAX_EPOCHS}\")\n",
    "print(f\"{'  Early Stop Patience:':<25} {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"{'  Device:':<25} {device.type.upper()}\")\n",
    "print(f\"{'  Loss Function:':<25} CrossEntropyLoss (weighted)\")\n",
    "print(f\"{'  Optimizer:':<25} AdamW\")\n",
    "print(f\"{'  LR Scheduler:':<25} ReduceLROnPlateau\")\n",
    "print(\"=\"*60 + \"\\\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d3c17",
   "metadata": {},
   "source": [
    "### TRAINING & VALIDATION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_k_accuracy(outputs, labels, k=5):\n",
    "    \"\"\"Calculate top-k accuracy\"\"\"\n",
    "    _, topk_preds = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct = topk_preds.eq(labels.view(-1, 1).expand_as(topk_preds))\n",
    "    return correct.sum().item()\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=MAX_EPOCHS):\n",
    "    \"\"\"\n",
    "    Enhanced training loop with:\n",
    "    - Top-5 accuracy tracking\n",
    "    - Early stopping\n",
    "    - Gradient clipping\n",
    "    - Learning rate tracking\n",
    "    - Overfitting detection\n",
    "    \"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "    epochs_without_improvement = 0\n",
    "    current_lr = LEARNING_RATE\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(\"üéØ STARTING TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\\\n{'='*80}\")\n",
    "        print(f\"üìÜ Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        epoch_metrics = {}\n",
    "\n",
    "        # TRAIN & VALIDATION LOOP\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_top5_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Progress bar\n",
    "            loop = tqdm(\n",
    "                dataloader,\n",
    "                desc=f\"{'üî• TRAIN' if phase == 'train' else '‚úÖ VAL  '}\",\n",
    "                leave=False,\n",
    "                ncols=100\n",
    "            )\n",
    "\n",
    "            for inputs, labels in loop:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        # Gradient clipping to prevent exploding gradients\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * batch_size\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                running_top5_corrects += calculate_top_k_accuracy(outputs, labels, k=5)\n",
    "                \n",
    "                # Update progress bar\n",
    "                current_acc = running_corrects / total_samples\n",
    "                loop.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{current_acc:.4f}'\n",
    "                })\n",
    "\n",
    "            # Calculate epoch metrics\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = running_corrects / total_samples\n",
    "            epoch_top5_acc = running_top5_corrects / total_samples\n",
    "\n",
    "            # Store metrics\n",
    "            epoch_metrics[f'{phase}_loss'] = epoch_loss\n",
    "            epoch_metrics[f'{phase}_acc'] = epoch_acc\n",
    "            epoch_metrics[f'{phase}_top5_acc'] = epoch_top5_acc\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"{phase.upper():>5} | Loss: {epoch_loss:.4f} | \"\n",
    "                  f\"Acc: {epoch_acc*100:>6.2f}% | Top-5: {epoch_top5_acc*100:>6.2f}%\")\n",
    "\n",
    "        # Update learning rate scheduler (based on validation loss)\n",
    "        scheduler.step(epoch_metrics['val_loss'])\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save metrics to history\n",
    "        history[\"train_loss\"].append(epoch_metrics['train_loss'])\n",
    "        history[\"val_loss\"].append(epoch_metrics['val_loss'])\n",
    "        history[\"train_acc\"].append(epoch_metrics['train_acc'])\n",
    "        history[\"val_acc\"].append(epoch_metrics['val_acc'])\n",
    "        history[\"train_top5_acc\"].append(epoch_metrics['train_top5_acc'])\n",
    "        history[\"val_top5_acc\"].append(epoch_metrics['val_top5_acc'])\n",
    "        history[\"learning_rates\"].append(current_lr)\n",
    "        \n",
    "        # Check for overfitting\n",
    "        loss_gap = epoch_metrics['train_loss'] - epoch_metrics['val_loss']\n",
    "        acc_gap = epoch_metrics['train_acc'] - epoch_metrics['val_acc']\n",
    "        \n",
    "        if loss_gap < -0.1 or acc_gap > 0.1:\n",
    "            print(f\"‚ö†Ô∏è  Overfitting detected: Train-Val gap = {acc_gap*100:.2f}% (acc), {loss_gap:.4f} (loss)\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_metrics['val_acc'] > best_val_acc:\n",
    "            best_val_acc = epoch_metrics['val_acc']\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "            epochs_without_improvement = 0\n",
    "            print(f\"‚ú® New best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"üìä No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"\\\\nüõë Early stopping triggered after {epoch+1} epochs\")\n",
    "            print(f\"   Best validation accuracy: {best_val_acc*100:.2f}% at epoch {best_epoch}\")\n",
    "            break\n",
    "\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(f\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(f\"   Best Epoch: {best_epoch}\")\n",
    "    print(f\"   Best Validation Accuracy: {best_val_acc*100:.2f}%\")\n",
    "    print(\"=\"*80 + \"\\\\n\")\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_epoch, best_val_acc\n",
    "\n",
    "CheckGPUBrief()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d49428",
   "metadata": {},
   "source": [
    "#### TRAIN THE MODEL & SAVE THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a8c8c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Training Instructions\n",
    "\n",
    "### To Train BOTH Models:\n",
    "\n",
    "**1. Train ResNet50:**\n",
    "- Set `MODEL_ARCH = 'resnet50'` in Global Configuration cell\n",
    "- Run all cells from \"Load Pretrained Model\" to \"TRAIN THE MODEL\"\n",
    "- Model will be saved as: `GTSRB_resnet50_E[epoch]_VAL[accuracy].pth`\n",
    "\n",
    "**2. Train EfficientNet-B3:**\n",
    "- Change `MODEL_ARCH = 'efficientnet_b3'` in Global Configuration cell\n",
    "- Re-run cells from \"Load Pretrained Model\" onwards\n",
    "- Model will be saved as: `GTSRB_efficientnet_b3_E[epoch]_VAL[accuracy].pth`\n",
    "\n",
    "### File Naming Examples:\n",
    "- `GTSRB_resnet50_E18_VAL98.45.pth` ‚Üí ResNet50, epoch 18, 98.45% val acc\n",
    "- `GTSRB_efficientnet_b3_E22_VAL99.12.pth` ‚Üí EfficientNet-B3, epoch 22, 99.12% val acc\n",
    "\n",
    "### Training Features:\n",
    "- ‚úÖ Early stopping (patience=7 epochs)\n",
    "- ‚úÖ Overfitting detection and warnings\n",
    "- ‚úÖ Adaptive learning rate (ReduceLROnPlateau)\n",
    "- ‚úÖ Gradient clipping\n",
    "- ‚úÖ Top-1 and Top-5 accuracy tracking\n",
    "- ‚úÖ Class-weighted loss for imbalanced data\n",
    "- ‚úÖ Dropout regularization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, best_epoch, best_val_acc = train_model(model, criterion, optimizer, scheduler, num_epochs=MAX_EPOCHS)\n",
    "\n",
    "# Generate model filename with architecture, epoch, and validation accuracy\n",
    "model_name = f\"GTSRB_{MODEL_ARCH}_E{best_epoch}_VAL{best_val_acc * 100:.2f}.pth\"\n",
    "model_path = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "\n",
    "# Save model state dict\n",
    "torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'val_acc': best_val_acc,\n",
    "    'model_arch': MODEL_ARCH,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'history': history\n",
    "}, model_path)\n",
    "\n",
    "print(f\"\\\\nüíæ Model saved successfully!\")\n",
    "print(f\"   File: {model_name}\")\n",
    "print(f\"   Path: {model_path}\")\n",
    "print(f\"   Best Epoch: {best_epoch}\")\n",
    "print(f\"   Validation Accuracy: {best_val_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa5af2",
   "metadata": {},
   "source": [
    "#### Plotting Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top-1 Accuracy\n",
    "axes[0, 0].plot(history[\"train_acc\"], label=\"Train Accuracy\", marker='o', linewidth=2)\n",
    "axes[0, 0].plot(history[\"val_acc\"], label=\"Val Accuracy\", marker='s', linewidth=2)\n",
    "axes[0, 0].set_title(\"üìà Top-1 Accuracy\", fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel(\"Epoch\")\n",
    "axes[0, 0].set_ylabel(\"Accuracy\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "\n",
    "# 2. Loss\n",
    "axes[0, 1].plot(history[\"train_loss\"], label=\"Train Loss\", marker='o', linewidth=2, color='orange')\n",
    "axes[0, 1].plot(history[\"val_loss\"], label=\"Val Loss\", marker='s', linewidth=2, color='red')\n",
    "axes[0, 1].set_title(\"üìâ Loss\", fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel(\"Epoch\")\n",
    "axes[0, 1].set_ylabel(\"Loss\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Top-5 Accuracy\n",
    "axes[1, 0].plot(history[\"train_top5_acc\"], label=\"Train Top-5\", marker='o', linewidth=2, color='green')\n",
    "axes[1, 0].plot(history[\"val_top5_acc\"], label=\"Val Top-5\", marker='s', linewidth=2, color='darkgreen')\n",
    "axes[1, 0].set_title(\"üéØ Top-5 Accuracy\", fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel(\"Epoch\")\n",
    "axes[1, 0].set_ylabel(\"Top-5 Accuracy\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "\n",
    "# 4. Learning Rate\n",
    "axes[1, 1].plot(history[\"learning_rates\"], marker='o', linewidth=2, color='purple')\n",
    "axes[1, 1].set_title(\"üìä Learning Rate Schedule\", fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel(\"Epoch\")\n",
    "axes[1, 1].set_ylabel(\"Learning Rate\")\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f\"Training Curves - {MODEL_ARCH.upper()}\", fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training curves displayed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea41fcfb",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix provides a more detailed view of classification results.\n",
    "It shows how many times the model correctly predicted each class versus how many times it confused it with another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20340ce8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä POST-PROCESSING & EVALUATION\n",
    "\n",
    "Comprehensive evaluation of the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1fa4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Collect predictions on test set\n",
    "print(\"üîç Collecting model predictions on test set...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []  # Store probabilities for confidence analysis\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"‚úÖ Predictions collected successfully.\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# üßÆ Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Get class names from Meta.csv\n",
    "meta_df = pd.read_csv(META_CSV)\n",
    "class_names = meta_df['ClassId'].astype(str).tolist()\n",
    "\n",
    "# ‚úÖ Compute overall accuracy\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üéØ Overall Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ‚úÖ Compute per-class accuracy\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "best_class_idx = np.argmax(per_class_acc)\n",
    "worst_class_idx = np.argmin(per_class_acc)\n",
    "print(f\"üèÜ Best performing class: Class {best_class_idx} with {per_class_acc[best_class_idx]*100:.2f}% accuracy\")\n",
    "print(f\"‚ö†Ô∏è  Worst performing class: Class {worst_class_idx} with {per_class_acc[worst_class_idx]*100:.2f}% accuracy\")\n",
    "\n",
    "# ‚úÖ Identify the most confused class pair\n",
    "cm_copy = cm.copy().astype(float)\n",
    "np.fill_diagonal(cm_copy, 0)\n",
    "most_confused_idx = np.unravel_index(np.argmax(cm_copy), cm_copy.shape)\n",
    "most_confused_value = int(cm_copy[most_confused_idx])\n",
    "print(f\"üîÑ Most confused pair: Class {most_confused_idx[0]} ‚Üî Class {most_confused_idx[1]} ({most_confused_value} misclassifications)\")\n",
    "\n",
    "# üìä Additional metrics\n",
    "balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "print(f\"‚öñÔ∏è  Balanced Accuracy: {balanced_acc * 100:.2f}%\")\n",
    "\n",
    "# Average confidence for correct and incorrect predictions\n",
    "correct_mask = all_preds == all_labels\n",
    "correct_confidences = [all_probs[i][all_preds[i]] for i in range(len(all_preds)) if correct_mask[i]]\n",
    "incorrect_confidences = [all_probs[i][all_preds[i]] for i in range(len(all_preds)) if not correct_mask[i]]\n",
    "\n",
    "avg_correct_conf = np.mean(correct_confidences) if len(correct_confidences) > 0 else 0\n",
    "avg_incorrect_conf = np.mean(incorrect_confidences) if len(incorrect_confidences) > 0 else 0\n",
    "\n",
    "print(f\"‚úÖ Average confidence (correct predictions): {avg_correct_conf * 100:.2f}%\")\n",
    "print(f\"‚ùå Average confidence (incorrect predictions): {avg_incorrect_conf * 100:.2f}%\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# üìà Plot confusion matrix (normalized and absolute)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "# Absolute confusion matrix\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(NUM_CLASSES))\n",
    "disp1.plot(ax=axes[0], cmap='Blues', xticks_rotation=90, colorbar=True)\n",
    "axes[0].set_title(\"Confusion Matrix (Absolute Counts)\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=range(NUM_CLASSES))\n",
    "disp2.plot(ax=axes[1], cmap='Greens', xticks_rotation=90, colorbar=True, values_format='.2f')\n",
    "axes[1].set_title(\"Confusion Matrix (Normalized)\", fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f\"Confusion Matrices - {MODEL_ARCH.upper()}\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìÑ Classification report\n",
    "print(\"\\nüìä Classification Report Summary:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(NUM_CLASSES)], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c4a74",
   "metadata": {},
   "source": [
    "### Per-Class Detailed Metrics\n",
    "\n",
    "Breakdown of precision, recall, and F1-score for each traffic sign class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54261976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Per-Class Detailed Metrics Table\n",
    "precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "print(\"\\nüìä Detailed Per-Class Metrics:\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Class':<8} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Sort by F1-score for better visibility\n",
    "class_metrics = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_metrics.append({\n",
    "        'class': i,\n",
    "        'accuracy': per_class_acc[i] * 100,\n",
    "        'precision': precision[i] * 100,\n",
    "        'recall': recall[i] * 100,\n",
    "        'f1': f1[i] * 100,\n",
    "        'support': int(support[i])\n",
    "    })\n",
    "\n",
    "# Display top 10 and bottom 10 classes\n",
    "sorted_by_f1 = sorted(class_metrics, key=lambda x: x['f1'], reverse=True)\n",
    "\n",
    "print(\"üèÜ TOP 10 PERFORMING CLASSES:\")\n",
    "for metric in sorted_by_f1[:10]:\n",
    "    print(f\"{metric['class']:<8} {metric['accuracy']:>6.2f}%      {metric['precision']:>6.2f}%      \"\n",
    "          f\"{metric['recall']:>6.2f}%      {metric['f1']:>6.2f}%      {metric['support']:<10}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  BOTTOM 10 PERFORMING CLASSES:\")\n",
    "for metric in sorted_by_f1[-10:]:\n",
    "    print(f\"{metric['class']:<8} {metric['accuracy']:>6.2f}%      {metric['precision']:>6.2f}%      \"\n",
    "          f\"{metric['recall']:>6.2f}%      {metric['f1']:>6.2f}%      {metric['support']:<10}\")\n",
    "\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Compute macro and weighted averages\n",
    "macro_precision = np.mean(precision) * 100\n",
    "macro_recall = np.mean(recall) * 100\n",
    "macro_f1 = np.mean(f1) * 100\n",
    "\n",
    "weighted_precision = np.average(precision, weights=support) * 100\n",
    "weighted_recall = np.average(recall, weights=support) * 100\n",
    "weighted_f1 = np.average(f1, weights=support) * 100\n",
    "\n",
    "print(f\"\\nüìä AGGREGATE METRICS:\")\n",
    "print(f\"  Macro Avg:    Precision={macro_precision:.2f}%  Recall={macro_recall:.2f}%  F1={macro_f1:.2f}%\")\n",
    "print(f\"  Weighted Avg: Precision={weighted_precision:.2f}%  Recall={weighted_recall:.2f}%  F1={weighted_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226b8e9",
   "metadata": {},
   "source": [
    "### Performance Visualizations\n",
    "\n",
    "Additional charts for comprehensive model analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Performance Visualization - 6 Panel Analysis\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 16))\n",
    "\n",
    "# 1. Per-Class Accuracy Bar Chart\n",
    "axes[0, 0].bar(range(NUM_CLASSES), per_class_acc * 100, color='steelblue', alpha=0.7)\n",
    "axes[0, 0].axhline(y=accuracy * 100, color='red', linestyle='--', linewidth=2, label=f'Overall Avg: {accuracy*100:.2f}%')\n",
    "axes[0, 0].set_xlabel('Class ID')\n",
    "axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "axes[0, 0].set_title('Per-Class Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Precision, Recall, F1-Score Comparison\n",
    "x_pos = np.arange(NUM_CLASSES)\n",
    "width = 0.25\n",
    "axes[0, 1].bar(x_pos - width, precision * 100, width, label='Precision', alpha=0.8, color='green')\n",
    "axes[0, 1].bar(x_pos, recall * 100, width, label='Recall', alpha=0.8, color='orange')\n",
    "axes[0, 1].bar(x_pos + width, f1 * 100, width, label='F1-Score', alpha=0.8, color='purple')\n",
    "axes[0, 1].set_xlabel('Class ID')\n",
    "axes[0, 1].set_ylabel('Score (%)')\n",
    "axes[0, 1].set_title('Precision, Recall, F1-Score per Class', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Class Support Distribution\n",
    "axes[1, 0].bar(range(NUM_CLASSES), support, color='coral', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Class ID')\n",
    "axes[1, 0].set_ylabel('Number of Samples')\n",
    "axes[1, 0].set_title('Test Set Class Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Confidence Distribution (Correct vs Incorrect)\n",
    "axes[1, 1].hist(correct_confidences, bins=30, alpha=0.7, label='Correct Predictions', color='green', edgecolor='black')\n",
    "axes[1, 1].hist(incorrect_confidences, bins=30, alpha=0.7, label='Incorrect Predictions', color='red', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Confidence Score')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Prediction Confidence Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 5. Top-10 Most Confused Class Pairs\n",
    "cm_off_diagonal = cm.copy().astype(float)\n",
    "np.fill_diagonal(cm_off_diagonal, 0)\n",
    "confused_pairs = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        if i != j and cm_off_diagonal[i, j] > 0:\n",
    "            confused_pairs.append((i, j, int(cm_off_diagonal[i, j])))\n",
    "\n",
    "confused_pairs_sorted = sorted(confused_pairs, key=lambda x: x[2], reverse=True)[:10]\n",
    "pair_labels = [f\"{p[0]}‚Üí{p[1]}\" for p in confused_pairs_sorted]\n",
    "pair_counts = [p[2] for p in confused_pairs_sorted]\n",
    "\n",
    "axes[2, 0].barh(pair_labels, pair_counts, color='indianred', alpha=0.8)\n",
    "axes[2, 0].set_xlabel('Number of Misclassifications')\n",
    "axes[2, 0].set_ylabel('Class Pair (True‚ÜíPredicted)')\n",
    "axes[2, 0].set_title('Top-10 Most Confused Class Pairs', fontsize=13, fontweight='bold')\n",
    "axes[2, 0].grid(True, alpha=0.3, axis='x')\n",
    "axes[2, 0].invert_yaxis()\n",
    "\n",
    "# 6. Accuracy vs Support Scatter Plot\n",
    "axes[2, 1].scatter(support, per_class_acc * 100, s=100, alpha=0.6, c=range(NUM_CLASSES), cmap='viridis', edgecolors='black')\n",
    "axes[2, 1].set_xlabel('Test Set Support (samples)')\n",
    "axes[2, 1].set_ylabel('Accuracy (%)')\n",
    "axes[2, 1].set_title('Accuracy vs Class Support', fontsize=13, fontweight='bold')\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation coefficient\n",
    "correlation = np.corrcoef(support, per_class_acc)[0, 1]\n",
    "axes[2, 1].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                transform=axes[2, 1].transAxes, fontsize=11, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle(f'Comprehensive Performance Analysis - {MODEL_ARCH.upper()}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Performance visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe3bdb",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "Analyzing misclassification patterns to understand model weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ed2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Error Analysis\n",
    "print(\"üîç Analyzing misclassification patterns...\\n\")\n",
    "\n",
    "# Find indices of misclassified samples\n",
    "misclassified_indices = np.where(all_preds != all_labels)[0]\n",
    "num_errors = len(misclassified_indices)\n",
    "\n",
    "print(f\"‚ùå Total misclassifications: {num_errors} out of {len(all_labels)} ({num_errors/len(all_labels)*100:.2f}%)\")\n",
    "\n",
    "# Analyze error distribution by true class\n",
    "error_by_class = {}\n",
    "for idx in misclassified_indices:\n",
    "    true_class = all_labels[idx]\n",
    "    pred_class = all_preds[idx]\n",
    "    \n",
    "    if true_class not in error_by_class:\n",
    "        error_by_class[true_class] = []\n",
    "    error_by_class[true_class].append(pred_class)\n",
    "\n",
    "# Classes with most errors\n",
    "class_error_counts = {cls: len(errors) for cls, errors in error_by_class.items()}\n",
    "sorted_error_classes = sorted(class_error_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nüî¥ Top-10 Classes with Most Errors:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Class':<10} {'Errors':<12} {'Error Rate':<15}\")\n",
    "print(\"=\"*60)\n",
    "for cls, error_count in sorted_error_classes[:10]:\n",
    "    total_samples = support[cls]\n",
    "    error_rate = (error_count / total_samples) * 100 if total_samples > 0 else 0\n",
    "    print(f\"{cls:<10} {error_count:<12} {error_rate:>6.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Confidence analysis for errors\n",
    "print(f\"\\nüìä Confidence Analysis for Misclassifications:\")\n",
    "if len(incorrect_confidences) > 0:\n",
    "    conf_quartiles = np.percentile(incorrect_confidences, [25, 50, 75])\n",
    "    print(f\"  25th percentile: {conf_quartiles[0]*100:.2f}%\")\n",
    "    print(f\"  50th percentile (median): {conf_quartiles[1]*100:.2f}%\")\n",
    "    print(f\"  75th percentile: {conf_quartiles[2]*100:.2f}%\")\n",
    "    \n",
    "    high_confidence_errors = sum(1 for c in incorrect_confidences if c > 0.8)\n",
    "    print(f\"  High-confidence errors (>80%): {high_confidence_errors} ({high_confidence_errors/len(incorrect_confidences)*100:.1f}%)\")\n",
    "\n",
    "# Error patterns - which classes are commonly mistaken for each other\n",
    "print(f\"\\nüîÑ Most Common Misclassification Patterns:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'True Class':<15} {'Predicted As':<15} {'Count':<12} {'% of Class':<15}\")\n",
    "print(\"=\"*70)\n",
    "for true_cls, pred_list in sorted(error_by_class.items(), key=lambda x: len(x[1]), reverse=True)[:5]:\n",
    "    pred_counts = {}\n",
    "    for pred in pred_list:\n",
    "        pred_counts[pred] = pred_counts.get(pred, 0) + 1\n",
    "    \n",
    "    most_common_pred = max(pred_counts.items(), key=lambda x: x[1])\n",
    "    pct_of_class = (most_common_pred[1] / support[true_cls]) * 100\n",
    "    print(f\"{true_cls:<15} {most_common_pred[0]:<15} {most_common_pred[1]:<12} {pct_of_class:>6.2f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ Error analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce177ad3",
   "metadata": {},
   "source": [
    "### Final Summary Report\n",
    "\n",
    "Comprehensive summary of model performance and key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78384bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Final Summary Report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*25 + \"üéØ MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüì¶ Model Architecture: {MODEL_ARCH.upper()}\")\n",
    "print(f\"üìä Dataset: GTSRB (German Traffic Sign Recognition Benchmark)\")\n",
    "print(f\"üî¢ Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"üß™ Test Set Size: {len(all_labels)} images\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"üìà OVERALL PERFORMANCE METRICS:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"  Overall Accuracy:        {accuracy * 100:>6.2f}%\")\n",
    "print(f\"  Balanced Accuracy:       {balanced_acc * 100:>6.2f}%\")\n",
    "print(f\"  Macro Precision:         {macro_precision:>6.2f}%\")\n",
    "print(f\"  Macro Recall:            {macro_recall:>6.2f}%\")\n",
    "print(f\"  Macro F1-Score:          {macro_f1:>6.2f}%\")\n",
    "print(f\"  Weighted Precision:      {weighted_precision:>6.2f}%\")\n",
    "print(f\"  Weighted Recall:         {weighted_recall:>6.2f}%\")\n",
    "print(f\"  Weighted F1-Score:       {weighted_f1:>6.2f}%\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"‚úÖ BEST PERFORMING CLASSES (Top-3):\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "for i, metric in enumerate(sorted_by_f1[:3], 1):\n",
    "    print(f\"  {i}. Class {metric['class']:2d}: F1={metric['f1']:6.2f}%, \"\n",
    "          f\"Accuracy={metric['accuracy']:6.2f}%, Support={metric['support']}\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"‚ö†Ô∏è  WORST PERFORMING CLASSES (Bottom-3):\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "for i, metric in enumerate(sorted_by_f1[-3:], 1):\n",
    "    print(f\"  {i}. Class {metric['class']:2d}: F1={metric['f1']:6.2f}%, \"\n",
    "          f\"Accuracy={metric['accuracy']:6.2f}%, Support={metric['support']}\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"üîÑ CONFUSION INSIGHTS:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"  Most confused pair: Class {most_confused_idx[0]} ‚Üí Class {most_confused_idx[1]} \"\n",
    "      f\"({most_confused_value} misclassifications)\")\n",
    "print(f\"  Total misclassifications: {num_errors}\")\n",
    "print(f\"  Error rate: {num_errors/len(all_labels)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"üé≤ CONFIDENCE STATISTICS:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"  Avg confidence (correct):   {avg_correct_conf * 100:>6.2f}%\")\n",
    "print(f\"  Avg confidence (incorrect): {avg_incorrect_conf * 100:>6.2f}%\")\n",
    "print(f\"  Confidence gap:             {(avg_correct_conf - avg_incorrect_conf) * 100:>6.2f}%\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"üíæ MODEL ARTIFACTS:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"  Saved model: GTSRB_{MODEL_ARCH}_E{{epoch}}_VAL{{accuracy}}.pth\")\n",
    "print(f\"  Training history: Stored in 'history' dictionary\")\n",
    "print(f\"  Metrics tracked: Top-1 Acc, Top-5 Acc, Loss, Learning Rate\")\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"üöÄ TRAINING CONFIGURATION:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"  Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (patience=3, factor=0.5)\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Max epochs: {MAX_EPOCHS}\")\n",
    "print(f\"  Early stopping patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"  Dropout rate: {DROPOUT_RATE}\")\n",
    "print(f\"  Gradient clipping: max_norm={MAX_GRAD_NORM}\")\n",
    "print(f\"  Validation split: {VALIDATION_SPLIT*100:.0f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\" \"*20 + \"‚úÖ EVALUATION COMPLETE!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
